Nets 2130 Homework 1 Writeup

# Zooniverse

## Project Selection and Tasks

I selected six diverse projects on Zooniverse to explore different aspects of citizen science crowdsourcing:

<img width="1257" alt="Screenshot 2024-09-29 at 10 07 52â€¯AM" src="https://github.com/user-attachments/assets/4c97f28c-065e-4d3e-a8a7-396e8b7b798f">


1. **Exosteroids and Galaxy Zoo**: These astronomy-focused projects are among Zooniverse's most popular and well-known. They involve volunteers identifying stars, galaxies, and asteroids.

2. **Shark Spy and Wildlife Watch**: As a wildlife enthusiast, I chose these projects to apply my animal knowledge to classification tasks. They offered insight into how crowdsourcing works in biodiversity research.

3. **Sudan Road Access**: This project stood out for its real-world impact, helping to map roads and infrastructure for aid delivery in Sudan. It demonstrates how crowdsourcing can directly benefit humanitarian efforts.

4. **Reading Emotions**: This psychology-related project caught my attention as it aligns with my minor in psychology. It involves more complex inference tasks compared to simple classification.

The tasks primarily involved classification, which humans can often perform more accurately than machines in certain contexts. For example:

- Identifying sharks or birds in images (Shark Spy and Wildlife Watch)
- Classifying galaxy types and asteroid characteristics (Galaxy Zoo and Exosteroids)
- Inferring emotions from written statements (Reading Emotions)
- Identifying infrastructure features like bridges and unpaved roads in satellite imagery (Sudan Road Access)

These tasks highlight a key strength of human crowdsourcing: the ability to make nuanced judgments that may be challenging for AI. For instance, distinguishing between a shark and other fish in murky water, or interpreting the emotional subtext of a written statement.

## Task Instructions and User Experience

Most project instructions were clear and easy to follow, with step-by-step guides available for each task. However, I encountered some usability issues:

1. In Shark Spy and Wildlife Watch, while the basic instructions were clear, identifying specific species required clicking through multiple images for reference. This process could be streamlined.

2. The Wildlife Watch interface presented an unnecessarily large set of animal options, most of which were irrelevant to the actual tasks. This cluttered the UI and made bird identification more cumbersome than necessary.

3. The Sudan Road Access project initially posed challenges in distinguishing between roads and rivers in satellite imagery. This highlights the importance of providing clear visual examples and guidelines for more complex tasks.

Despite these minor issues, Zooniverse generally provides a user-friendly experience with easily accessible instructions and intuitive interfaces for most projects.

## Completed Projects and Publications

Zooniverse's model of citizen science has led to numerous scientific publications. One notable example is the discovery of "Green Pea" galaxies, detailed in the paper "Galaxy Zoo Green Peas: discovery of a class of compact extremely star-forming galaxies."

This project showcases the unique advantage of human classifiers in scientific research. Volunteers were able to identify and investigate unusual objects that might have been overlooked by automated systems. The collective effort of citizen scientists helped establish the common characteristics of these rare galaxies, leading to a significant astronomical discovery.

This example illustrates how crowdsourcing can:

1. Leverage human pattern recognition skills for scientific breakthroughs
2. Enable large-scale data analysis that would be impractical for a small research team
3. Engage the public in the scientific process, potentially increasing science literacy and interest

## Time Investment

I spent approximately 30-40 minutes on most projects, with less engaging ones receiving about 15 minutes of attention. Individual tasks typically took around 15 seconds to complete.

This time investment reveals both strengths and limitations of the Zooniverse model:

- **Strength**: Quick, bite-sized tasks allow for easy participation and rapid data collection.
- **Limitation**: The repetitive nature of tasks can lead to fatigue or boredom, potentially affecting long-term volunteer retention.

## Volunteer Motivation

Zooniverse relies entirely on volunteers, which raises interesting questions about motivation in crowdsourcing. Several factors likely contribute to user engagement:

1. **Scientific Impact**: Many projects directly contribute to research, giving volunteers a sense of purpose and connection to scientific discovery.

2. **Real-World Applications**: Projects like Sudan Road Access offer tangible humanitarian benefits, appealing to altruistic motivations.

3. **User Experience**: Zooniverse's well-designed interface and clear instructions lower the barrier to entry and make participation enjoyable.

4. **Topic Interest**: The diverse range of projects allows volunteers to contribute to fields they're passionate about, from astronomy to wildlife conservation.

5. **Gamification Elements**: Some projects incorporate progress tracking and achievement systems, adding a game-like element to participation.

However, the platform faces challenges in maintaining long-term engagement. The repetitive nature of tasks can lead to boredom, as I experienced after about 30 minutes of continuous work. To address this, Zooniverse could consider:

- Implementing more varied task types within projects
- Offering more frequent feedback on the impact of contributions
- Developing a robust community system to foster social connections among volunteers

## Ethical Considerations and Future Directions

While Zooniverse's volunteer model avoids many of the ethical concerns associated with paid crowdsourcing platforms, it raises other considerations:

1. **Data Privacy**: How is volunteer-submitted data protected and used?
2. **Intellectual Property**: How are volunteers credited for their contributions to scientific discoveries?
3. **Inclusivity**: Are there barriers to participation that might exclude certain groups?

Looking ahead, Zooniverse and similar platforms could explore:

1. Enhanced feedback mechanisms to show volunteers the direct impact of their work
2. Integration of machine learning to complement human efforts and tackle more complex tasks
3. Expanded educational resources to deepen volunteers' understanding of the scientific process
4. Partnerships with schools and universities to integrate citizen science into curricula

In conclusion, Zooniverse demonstrates the potential of citizen science crowdsourcing to advance scientific research and address real-world challenges. By leveraging human cognitive abilities and intrinsic motivation, it offers a unique model that complements other forms of crowdsourcing and traditional research methodologies.
